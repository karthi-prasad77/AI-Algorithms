{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the working behind LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exists at Path: /home/karthi/AI-Algorithms/NLP/Data/NationalNames.csv\n"
     ]
    }
   ],
   "source": [
    "# get the data path\n",
    "current_dir = os.getcwd()\n",
    "data_path = \"Data\"\n",
    "csv_folderpath = os.path.dirname(current_dir)\n",
    "csv_file_name = \"NationalNames.csv\"\n",
    "csv_full_path = os.path.join(csv_folderpath + f\"/{data_path}\", csv_file_name)\n",
    "\n",
    "# check the file exist or not\n",
    "if os.path.exists(csv_full_path):\n",
    "    print(f\"Data exists at Path: {csv_full_path}\")\n",
    "else:\n",
    "    print(f\"Data doesn't exist in the Path : {csv_full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas detected the CSV Data. üêº\n"
     ]
    }
   ],
   "source": [
    "# read the dataset from the path\n",
    "raw_data = pd.read_csv(csv_full_path)\n",
    "\n",
    "if raw_data is not None:\n",
    "    print(\"Pandas detected the CSV Data. üêº\")\n",
    "else:\n",
    "    print(\"Pandas could not able to detect the csv file. üò•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"Name\"] = raw_data[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mary</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Anna</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Emma</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>1880</td>\n",
       "      <td>F</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       Name  Year Gender  Count\n",
       "0   1       Mary  1880      F   7065\n",
       "1   2       Anna  1880      F   2604\n",
       "2   3       Emma  1880      F   2003\n",
       "3   4  Elizabeth  1880      F   1939\n",
       "4   5     Minnie  1880      F   1746"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Mary'],\n",
       "       ['Anna'],\n",
       "       ['Emma'],\n",
       "       ...,\n",
       "       ['Jens'],\n",
       "       ['Julious'],\n",
       "       ['Lindsay']], shape=(10000, 1), dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first 10000 names\n",
    "raw_data = np.array(raw_data[\"Name\"][:10000]).reshape(-1, 1)\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the names into lowercase\n",
    "raw_data = [x.lower() for x in raw_data[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample name: \n",
      "[['mary']\n",
      " ['anna']\n",
      " ['emma']\n",
      " ['elizabeth']\n",
      " ['minnie']]\n",
      "Shape of the data: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.array(raw_data).reshape(-1, 1)\n",
    "\n",
    "# lets see some sample names\n",
    "print(f\"Sample name: \\n{raw_data[:5]}\")\n",
    "\n",
    "# shape of the data\n",
    "print(f\"Shape of the data: {raw_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name max length: 12\n"
     ]
    }
   ],
   "source": [
    "# there was a difference in the each name length\n",
    "# need to make all in same length\n",
    "transformed_data = np.copy(raw_data)\n",
    "\n",
    "# find the max length\n",
    "max_length = 0\n",
    "for i in range(len(transformed_data)):\n",
    "    max_length = max(max_length, len(transformed_data[i, 0]))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Name max length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data: \n",
      " [['mary........']\n",
      " ['anna........']\n",
      " ['emma........']\n",
      " ['elizabeth...']\n",
      " ['minnie......']]\n"
     ]
    }
   ],
   "source": [
    "# make each name into same length\n",
    "for i in range(len(transformed_data)):\n",
    "    length = (max_length - len(transformed_data[i, 0]))\n",
    "    string = '.'*length\n",
    "    transformed_data[i, 0] = ''.join([transformed_data[i, 0], string])\n",
    "\n",
    "print(\"Transformed Data: \\n\", transformed_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocab: 120000\n"
     ]
    }
   ],
   "source": [
    "# store the vocabulary\n",
    "vocab = list()\n",
    "\n",
    "for name in transformed_data[:,0]:\n",
    "    vocab.extend(list(name))\n",
    "\n",
    "print(f\"Length of the vocab: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the vocab after removing duplicates: 27\n",
      "\n",
      "Vocab: {'w', 'j', 'o', 'm', 'v', 't', 'a', 'f', 'y', 'n', 'b', 'u', 'e', 'p', 'l', 'k', 'x', '.', 'i', 'z', 'r', 'g', 'c', 'd', 's', 'q', 'h'}\n"
     ]
    }
   ],
   "source": [
    "# remove dupicates in vocab\n",
    "vocab = set(vocab)\n",
    "\n",
    "print(f\"Length of the vocab after removing duplicates: {len(vocab)}\")\n",
    "print(f\"\\nVocab: {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sorting the vocab in ascending order: \n",
      " ['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# sort the vocabulory\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "print(f\"After sorting the vocab in ascending order: \\n {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to Id: \n",
      " {'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "Id to Character: \n",
      " {0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# map char to id and id to char\n",
    "char_to_id = dict()\n",
    "id_to_char = dict()\n",
    "\n",
    "for index, character in enumerate(vocab):\n",
    "    char_to_id[character] = index\n",
    "    id_to_char[index] = character\n",
    "\n",
    "print(f\"Character to Id: \\n {char_to_id}\")\n",
    "print(f\"Id to Character: \\n {id_to_char}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into batches for training\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for i in range(len(transformed_data) - BATCH_SIZE + 1):\n",
    "    start = i * BATCH_SIZE\n",
    "    end = start + BATCH_SIZE\n",
    "\n",
    "    # batch data\n",
    "    batch_data = transformed_data[start:end]\n",
    "\n",
    "    if (len(batch_data) != BATCH_SIZE):\n",
    "        break\n",
    "\n",
    "    # convert each character in each word into one hot encoding\n",
    "    char_list = []\n",
    "\n",
    "    for c in range(len(batch_data[0][0])):\n",
    "        batch_dataset = np.zeros([BATCH_SIZE,len(vocab)])\n",
    "\n",
    "        for n in range(BATCH_SIZE):\n",
    "            name = batch_data[n][0]\n",
    "            char_index = char_to_id[name[c]]\n",
    "            batch_dataset[n, char_index] = 1.0\n",
    "\n",
    "        char_list.append(batch_dataset)\n",
    "\n",
    "    training_data.append(char_list)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some of the hyper parameters\n",
    "\n",
    "# number of input units or embedding size\n",
    "INPUT_UNITS = 100\n",
    "\n",
    "# number of hidden units\n",
    "HIDDEN_UNITS = 256\n",
    "\n",
    "# number of output units, i.e, vocab size\n",
    "OUTPUT_UNITS = len(vocab)\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.005\n",
    "\n",
    "# adam optimizer parameters\n",
    "beta_01 = 0.90\n",
    "beta_02 = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "\n",
    "# sigmoid activation function\n",
    "def Sigmoid(x: np.array):\n",
    "    return (1 / (np.exp(-x)))\n",
    "\n",
    "# tanh activation function\n",
    "def TanH(x: np.array):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# softmax activation function\n",
    "def Softmax(x: np.array):\n",
    "    exp_X = np.exp(x)\n",
    "    exp_X_Sum = np.sum(exp_X, axis=1).reshape(-1, 1)\n",
    "    exp_X = exp_X / exp_X_Sum\n",
    "    return exp_X\n",
    "\n",
    "def tanh_derivative(x: np.array):\n",
    "    return (1 - (x ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
